<!doctype html><html lang=en dir=auto data-theme=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Autonomous Octocopter with Real-Time Object Detection | Brandon's Technical Blog</title><meta name=keywords content="octocopter,jetson-nano,yolov3,autonomous-navigation,computer-vision,embedded-systems"><meta name=description content="Building an autonomous octocopter using Jetson Nano and YOLOv3 for real-time object detection"><meta name=author content="Brandon Geraci"><link rel=canonical href=http://localhost:1313/projects/autonomous-octocopter/><link crossorigin=anonymous href=/assets/css/stylesheet.343cc480b9ffc8f04ccbe5e968ad674880cab773ec19905e93033065c1e7a804.css integrity="sha256-NDzEgLn/yPBMy+XpaK1nSIDKt3PsGZBekwMwZcHnqAQ=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/favicon.ico><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/favicon-32x32.png><link rel=apple-touch-icon href=http://localhost:1313/apple-touch-icon.png><link rel=mask-icon href=http://localhost:1313/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=http://localhost:1313/projects/autonomous-octocopter/index.xml title=rss><link rel=alternate hreflang=en href=http://localhost:1313/projects/autonomous-octocopter/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><meta property="og:url" content="http://localhost:1313/projects/autonomous-octocopter/"><meta property="og:site_name" content="Brandon's Technical Blog"><meta property="og:title" content="Autonomous Octocopter with Real-Time Object Detection"><meta property="og:description" content="Building an autonomous octocopter using Jetson Nano and YOLOv3 for real-time object detection"><meta property="og:locale" content="en-us"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="Autonomous Octocopter with Real-Time Object Detection"><meta name=twitter:description content="Building an autonomous octocopter using Jetson Nano and YOLOv3 for real-time object detection"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Projects","item":"http://localhost:1313/projects/"},{"@type":"ListItem","position":2,"name":"Autonomous Octocopter with Real-Time Object Detection","item":"http://localhost:1313/projects/autonomous-octocopter/"}]}</script></head><body class=list id=top><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Brandon's Technical Blog (Alt + H)">Brandon's Technical Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/projects/ title=Projects><span>Projects</span></a></li><li><a href=http://localhost:1313/tags/ title=Tags><span>Tags</span></a></li><li><a href=http://localhost:1313/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/projects/>Projects</a></div><h1>Autonomous Octocopter with Real-Time Object Detection
<a href=/projects/autonomous-octocopter/index.xml title=RSS aria-label=RSS><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" height="23"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></h1><div class=post-description>Building an autonomous octocopter using Jetson Nano and YOLOv3 for real-time object detection</div></header><div class=post-content><h2 id=final-test-flight>Final Test Flight<a hidden class=anchor aria-hidden=true href=#final-test-flight>#</a></h2><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen" loading=eager referrerpolicy=strict-origin-when-cross-origin src="https://www.youtube.com/embed/TTFNwvMHMU8?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 title="YouTube video"></iframe></div><p>An autonomous flight system built around NVIDIA&rsquo;s Jetson Nano running YOLOv3 for real-time object detection and navigation.</p><h2 id=project-overview>Project Overview<a hidden class=anchor aria-hidden=true href=#project-overview>#</a></h2><p>During my time at the University of Minnesota Duluth, I built an autonomous octocopter that combined embedded AI with flight control systems. The goal was to create a drone capable of autonomous navigation using real-time computer vision.</p><h2 id=hardware-architecture>Hardware Architecture<a hidden class=anchor aria-hidden=true href=#hardware-architecture>#</a></h2><h3 id=core-components>Core Components<a hidden class=anchor aria-hidden=true href=#core-components>#</a></h3><p><strong>Flight Platform</strong></p><ul><li>Custom octocopter frame (8 motors for stability and redundancy)</li><li>Pixhawk/iX4 autopilot flight controller</li><li>GPS module for position tracking</li><li>Electronic Speed Controllers (ESCs) for motor control</li></ul><p><strong>AI Computing</strong></p><ul><li><strong>NVIDIA Jetson Nano</strong>: The brain of the operation<ul><li>128-core Maxwell GPU for YOLOv3 inference</li><li>Quad-core ARM A57 CPU</li><li>4GB LPDDR4 memory</li><li>Power consumption optimized for battery operation</li></ul></li></ul><p><strong>Sensors & Connectivity</strong></p><ul><li>USB camera for computer vision input</li><li>Telemetry radio for ground station communication</li><li>Battery monitoring system</li></ul><h3 id=hardware-integration-photos>Hardware Integration Photos<a hidden class=anchor aria-hidden=true href=#hardware-integration-photos>#</a></h3><p><img alt="Jetson Nano Bottom View 1" loading=lazy src=/images/autonomous-octocopter/20191226_113616.jpg>
<em>Bottom view showing the NVIDIA Jetson Nano mounted on the octocopter frame with the Pixhawk flight controller, GoPro camera, and power distribution system</em></p><p><img alt="Jetson Nano Bottom View 2" loading=lazy src=/images/autonomous-octocopter/20191228_141510.jpg>
<em>Close-up of the Jetson Nano with custom cooling fan, showing the USB ports, GPIO header, and power connections</em></p><h3 id=integration-challenges>Integration Challenges<a hidden class=anchor aria-hidden=true href=#integration-challenges>#</a></h3><p>Integrating the Jetson Nano with the flight controller required:</p><ul><li>Custom power distribution to provide clean 5V to the Jetson</li><li>UART/MAVLink communication between Jetson and Pixhawk</li><li>Weight optimization (every gram counts in flight time)</li><li>Vibration isolation for the camera</li></ul><h2 id=yolov3-real-time-object-detection>YOLOv3 Real-Time Object Detection<a hidden class=anchor aria-hidden=true href=#yolov3-real-time-object-detection>#</a></h2><h3 id=why-yolov3>Why YOLOv3?<a hidden class=anchor aria-hidden=true href=#why-yolov3>#</a></h3><p>YOLOv3 (You Only Look Once) was chosen for its balance of accuracy and speed - critical for real-time autonomous navigation:</p><ul><li>Single-pass detection (vs. region proposal methods)</li><li>~30 FPS on Jetson Nano with optimized models</li><li>Multi-scale prediction for objects at various distances</li></ul><h3 id=implementation-details>Implementation Details<a hidden class=anchor aria-hidden=true href=#implementation-details>#</a></h3><p><strong>Model Optimization</strong></p><ul><li>Used TensorRT to optimize YOLOv3 for Jetson&rsquo;s GPU</li><li>Reduced model precision (FP16) while maintaining accuracy</li><li>Custom training on aerial imagery dataset</li><li>Focused on detecting: people, vehicles, obstacles, landing markers</li></ul><p><strong>Real-Time Pipeline</strong></p><ol><li>Capture frame from camera</li><li>Preprocess and resize (416x416)</li><li>Run YOLOv3 inference on GPU</li><li>Parse detections and compute bounding boxes</li><li>Send navigation commands to flight controller</li></ol><h2 id=autonomous-navigation>Autonomous Navigation<a hidden class=anchor aria-hidden=true href=#autonomous-navigation>#</a></h2><p>The system operated in several modes:</p><p><strong>Object Tracking Mode</strong></p><ul><li>Lock onto and follow detected objects</li><li>Maintain safe distance using depth estimation</li><li>Automatic obstacle avoidance</li></ul><p><strong>Waypoint Navigation</strong></p><ul><li>GPS-based waypoint following</li><li>Object detection for dynamic obstacle avoidance</li><li>Return-to-home on low battery or signal loss</li></ul><p><strong>Landing Assistance</strong></p><ul><li>Visual marker detection for precision landing</li><li>Automatic descent when safe landing zone detected</li></ul><h2 id=results--performance>Results & Performance<a hidden class=anchor aria-hidden=true href=#results--performance>#</a></h2><p><img alt="Winter Flight Testing" loading=lazy src=/images/autonomous-octocopter/20191220_163642.jpg>
<em>Field testing in winter conditions - the octocopter proved reliable even in cold weather and challenging lighting conditions</em></p><h3 id=what-worked>What Worked<a hidden class=anchor aria-hidden=true href=#what-worked>#</a></h3><p><strong>Flight Stability</strong></p><ul><li>Octocopter configuration provided excellent stability</li><li>Motor redundancy allowed continued flight with single motor failure</li><li>Smooth integration between vision system and flight controller</li></ul><p><strong>Detection Performance</strong></p><ul><li>Consistent 25-30 FPS for object detection</li><li>Reliable detection at ranges of 5-50 meters</li><li>Low false positive rate after model fine-tuning</li></ul><p><strong>Autonomous Behavior</strong></p><ul><li>Successfully demonstrated autonomous takeoff, navigation, and landing</li><li>Real-time obstacle detection and avoidance</li><li>Stable tracking of moving objects</li></ul><h3 id=limitations>Limitations<a hidden class=anchor aria-hidden=true href=#limitations>#</a></h3><p><strong>Power Constraints</strong></p><ul><li>Jetson Nano added significant power draw</li><li>Flight time reduced to ~12 minutes (vs. ~18 without AI payload)</li><li>Battery weight trade-offs</li></ul><p><strong>Processing Latency</strong></p><ul><li>End-to-end latency of ~100ms (camera → decision → actuation)</li><li>Acceptable for many tasks, but challenging at high speeds</li></ul><p><strong>Weather Sensitivity</strong></p><ul><li>Computer vision performance degraded in poor lighting</li><li>Rain and fog significantly impacted detection reliability</li></ul><h2 id=technical-lessons-learned>Technical Lessons Learned<a hidden class=anchor aria-hidden=true href=#technical-lessons-learned>#</a></h2><p><strong>Embedded AI Optimization</strong></p><ul><li>TensorRT optimization was crucial for real-time performance</li><li>FP16 precision provided best speed/accuracy trade-off</li><li>Model quantization and pruning techniques extended battery life</li></ul><p><strong>Hardware Integration</strong></p><ul><li>Power filtering is critical - motor noise can crash the Jetson</li><li>Vibration isolation matters more than expected for vision</li><li>UART communication needs proper flow control for reliability</li></ul><p><strong>Autonomous Systems</strong></p><ul><li>Multiple redundant safety systems are non-negotiable</li><li>Failsafe behaviors need extensive testing</li><li>Always test with GPS spoofing and signal loss scenarios</li></ul><h2 id=future-improvements>Future Improvements<a hidden class=anchor aria-hidden=true href=#future-improvements>#</a></h2><p>If I were to rebuild this system today, I would:</p><p><strong>Hardware Upgrades</strong></p><ul><li>Jetson Xavier NX or Orin Nano (better performance per watt)</li><li>Stereo camera for depth perception</li><li>LiDAR for all-weather obstacle detection</li></ul><p><strong>Software Enhancements</strong></p><ul><li>Newer YOLO versions (YOLOv8/YOLOv9) for better efficiency</li><li>Visual-inertial odometry (VIO) for GPS-denied navigation</li><li>Reinforcement learning for more sophisticated flight behaviors</li></ul><p><strong>Safety Features</strong></p><ul><li>Parachute deployment system</li><li>Geofencing with multiple boundary layers</li><li>Computer vision-based landing zone assessment</li></ul><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><p>This project was an excellent introduction to autonomous robotics, combining:</p><ul><li>Embedded systems engineering</li><li>Real-time computer vision</li><li>Flight control systems</li><li>AI model optimization</li></ul><p>The experience of getting AI running efficiently on embedded hardware while meeting the strict timing requirements of autonomous flight taught valuable lessons about system integration and real-world constraints.</p><p>While commercial solutions have since surpassed this custom build, the hands-on experience of building an autonomous system from scratch provided insights that aren&rsquo;t available from using off-the-shelf solutions.</p><h2 id=technical-stack>Technical Stack<a hidden class=anchor aria-hidden=true href=#technical-stack>#</a></h2><ul><li><strong>Flight Controller</strong>: Pixhawk/iX4 Autopilot</li><li><strong>AI Platform</strong>: NVIDIA Jetson Nano</li><li><strong>Computer Vision</strong>: YOLOv3 + OpenCV</li><li><strong>Optimization</strong>: TensorRT, CUDA</li><li><strong>Communication</strong>: MAVLink protocol</li><li><strong>Development</strong>: Python, C++</li><li><strong>Ground Station</strong>: QGroundControl</li></ul><hr><p><em>This project was completed in 2018 as part of my studies at the University of Minnesota Duluth.</em></p></div></main><footer class=footer><span>&copy; 2025 <a href=http://localhost:1313/>Brandon's Technical Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script></body></html>