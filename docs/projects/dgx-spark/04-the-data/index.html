<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>The Data: 60 Runs Don't Lie | Brandon's Technical Blog</title><meta name=keywords content="dgx-spark,benchmarking,data,results"><meta name=description content="I ran 60 comprehensive benchmarks across three different model sizes. The results are consistent, surprising, and prove that unified memory + Docker cgroups = significant overhead."><meta name=author content="Brandon Geraci"><link rel=canonical href=https://brandongeraci.com/projects/dgx-spark/04-the-data/><link crossorigin=anonymous href=/assets/css/stylesheet.343cc480b9ffc8f04ccbe5e968ad674880cab773ec19905e93033065c1e7a804.css integrity="sha256-NDzEgLn/yPBMy+XpaK1nSIDKt3PsGZBekwMwZcHnqAQ=" rel="preload stylesheet" as=style><link rel=icon href=https://brandongeraci.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://brandongeraci.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://brandongeraci.com/favicon-32x32.png><link rel=apple-touch-icon href=https://brandongeraci.com/apple-touch-icon.png><link rel=mask-icon href=https://brandongeraci.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://brandongeraci.com/projects/dgx-spark/04-the-data/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><meta property="og:url" content="https://brandongeraci.com/projects/dgx-spark/04-the-data/"><meta property="og:site_name" content="Brandon's Technical Blog"><meta property="og:title" content="The Data: 60 Runs Don't Lie"><meta property="og:description" content="I ran 60 comprehensive benchmarks across three different model sizes. The results are consistent, surprising, and prove that unified memory + Docker cgroups = significant overhead."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="projects"><meta property="article:published_time" content="2025-11-08T13:00:00+00:00"><meta property="article:modified_time" content="2025-11-08T13:00:00+00:00"><meta property="article:tag" content="Dgx-Spark"><meta property="article:tag" content="Benchmarking"><meta property="article:tag" content="Data"><meta property="article:tag" content="Results"><meta property="og:see_also" content="https://brandongeraci.com/projects/dgx-spark/"><meta property="og:see_also" content="https://brandongeraci.com/projects/dgx-spark/06-kv-cache-deep-dive/"><meta property="og:see_also" content="https://brandongeraci.com/projects/dgx-spark/05-what-we-learned/"><meta property="og:see_also" content="https://brandongeraci.com/projects/dgx-spark/03-unified-memory-revelation/"><meta property="og:see_also" content="https://brandongeraci.com/projects/dgx-spark/02-mpi-chroot-nightmare/"><meta property="og:see_also" content="https://brandongeraci.com/projects/dgx-spark/01-the-mystery/"><meta name=twitter:card content="summary"><meta name=twitter:title content="The Data: 60 Runs Don't Lie"><meta name=twitter:description content="I ran 60 comprehensive benchmarks across three different model sizes. The results are consistent, surprising, and prove that unified memory + Docker cgroups = significant overhead."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Projects","item":"https://brandongeraci.com/projects/"},{"@type":"ListItem","position":2,"name":"DGX Spark Deep Dive","item":"https://brandongeraci.com/projects/dgx-spark/"},{"@type":"ListItem","position":3,"name":"The Data: 60 Runs Don't Lie","item":"https://brandongeraci.com/projects/dgx-spark/04-the-data/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"The Data: 60 Runs Don't Lie","name":"The Data: 60 Runs Don\u0027t Lie","description":"I ran 60 comprehensive benchmarks across three different model sizes. The results are consistent, surprising, and prove that unified memory + Docker cgroups = significant overhead.","keywords":["dgx-spark","benchmarking","data","results"],"articleBody":"The Comprehensive Test Plan Anecdotes are interesting. Single data points are suggestive. But 60 benchmark runs across multiple models? That’s science.\nHere’s what I did:\nTest Matrix 3 Models: DeepSeek-R1-Distill-Qwen-7B (7 billion parameters) Qwen2.5-72B-Instruct (72 billion parameters) GPT-OSS-120B (120 billion parameters, MXFP4 quantized) 2 Environments: Native (chroot) vs Container (Docker) 10 Iterations per model per environment Total: 60 benchmark runs Methodology Framework: TensorRT-LLM (trtllm-bench CLI) Workload: 50 requests, 128 output tokens per request Cooldown: 5 minutes + GPU temp check (\u003c 45°C) between runs Duration: ~14 hours total Metrics: Peak memory, KV cache, throughput, latency, temperature DeepSeek-7B Results My smallest model, but the most shocking results:\nMetric Native Container Difference Peak Memory 70.47 GiB 101.30 GiB +30.83 GiB (44% overhead!) KV Cache 44.31 GiB 16.57 GiB -27.74 GiB (63% less!) Throughput 119.79 tok/s 119.40 tok/s 0.3% difference Std Dev (σ) 0.55 0.16 Very stable Analysis: The 7B model shows the largest overhead at 30.8GB. Container KV cache is reduced to only 37% of native. That’s massive.\nGPT-OSS-120B Results The largest model (120B params, though MoE means 5.1B active):\nMetric Native Container Difference Peak Memory 71.72 GiB 93.43 GiB +21.71 GiB (30% overhead) KV Cache 43.19 GiB 23.65 GiB -19.54 GiB (45% less) Throughput 120.26 tok/s 120.41 tok/s -0.1% difference Std Dev (σ) 0.32 0.54 Very stable Analysis: Despite being the largest model, GPT-OSS shows moderate overhead due to MXFP4 quantization. Native still has 1.8x more KV cache.\nQwen2.5-72B Results The 72B parameter model - the sweet spot:\nMetric Native Container Difference Peak Memory 70.03 GiB 90.02 GiB +19.99 GiB (29% overhead) KV Cache 44.71 GiB 26.72 GiB -17.99 GiB (40% less) Throughput 119.33 tok/s 119.51 tok/s -0.2% difference Std Dev (σ) 0.28 0.20 Very stable Analysis: Qwen shows the most efficient memory usage of all models. Native mode has the highest KV cache at 44.71 GiB - even more than the 7B model!\nThe Pattern: Container Overhead Scales Look at the overhead across models:\nModel Size Overhead Pattern DeepSeek 7B +30.83 GiB (44%) Highest % Qwen 72B +19.99 GiB (29%) Middle GPT-OSS 120B +21.71 GiB (30%) Middle Insight: Overhead appears proportional to base memory usage, not model size. This suggests Docker’s cgroup accounting scales with allocation size, confirming our unified memory double-counting theory.\nPerformance Parity: The Good News Across all 60 runs, performance was virtually identical:\nThroughput Range: - Native: 119.33 - 120.26 tokens/sec - Container: 119.40 - 120.51 tokens/sec - Difference: \u003c 0.3% (within margin of error) Standard deviations were incredibly low (σ \u003c 0.6 tokens/sec), showing:\nExcellent thermal management Consistent GPU performance No thermal throttling The KV Cache Revelation This is the real story. Across all models:\nModel Native KV Container KV Ratio DeepSeek 44.31 GiB 16.57 GiB 2.7x more GPT-OSS 43.19 GiB 23.65 GiB 1.8x more Qwen 44.71 GiB 26.72 GiB 1.7x more Native mode provides 1.7-2.7x more KV cache across the board. This is huge for:\nLonger context windows Higher batch sizes Better concurrent request handling Overall throughput scaling Temperature Analysis Interestingly, containers ran slightly cooler:\nEnvironment Avg End Temp Range Native 60.6°C 59-61°C Container 58.6°C 57-59°C Why? Container overhead means more time in cooldown between runs. Actual compute time is the same, but total wall time is longer due to additional memory management.\nData Quality and Reproducibility All 60 runs completed successfully with:\n✅ 0 failures - Every benchmark completed ✅ Consistent results - Very low standard deviations ✅ Proper thermal management - No throttling ✅ Comprehensive logging - Full metadata saved Raw data available: GitHub - benchmark-spark/results\nInteractive Charts Want to explore the data visually? Check out our interactive results page with:\nPeak memory comparisons KV cache allocation charts Throughput performance graphs What This Proves After 60 runs across 3 models, the findings are clear:\nContainer overhead is real: 20-30 GB consistently KV cache reduction is significant: 1.7-2.7x less in containers Performance is identical: No speed penalty for native execution Pattern is consistent: Happens across all model sizes Root cause confirmed: Unified memory + cgroup double-counting This isn’t a fluke. This isn’t a configuration error. This is a fundamental architectural mismatch.\nNext up: What we learned, practical recommendations, and what we’re investigating next (spoiler: that KV cache scaling is fascinating).\nPrevious: ← Part 3: The Unified Memory Revelation\nNext: Part 5: What We Learned (And What’s Next) →\nGitHub Repo: benchmark-spark\nInteractive Charts: Results Dashboard\n","wordCount":"721","inLanguage":"en","datePublished":"2025-11-08T13:00:00Z","dateModified":"2025-11-08T13:00:00Z","author":{"@type":"Person","name":"Brandon Geraci"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://brandongeraci.com/projects/dgx-spark/04-the-data/"},"publisher":{"@type":"Organization","name":"Brandon's Technical Blog","logo":{"@type":"ImageObject","url":"https://brandongeraci.com/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://brandongeraci.com/ accesskey=h title="Brandon's Technical Blog (Alt + H)">Brandon's Technical Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://brandongeraci.com/projects/ title=Projects><span>Projects</span></a></li><li><a href=https://brandongeraci.com/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://brandongeraci.com/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://brandongeraci.com/>Home</a>&nbsp;»&nbsp;<a href=https://brandongeraci.com/projects/>Projects</a>&nbsp;»&nbsp;<a href=https://brandongeraci.com/projects/dgx-spark/>DGX Spark Deep Dive</a></div><h1 class="post-title entry-hint-parent">The Data: 60 Runs Don't Lie</h1><div class=post-description>I ran 60 comprehensive benchmarks across three different model sizes. The results are consistent, surprising, and prove that unified memory + Docker cgroups = significant overhead.</div><div class=post-meta><span title='2025-11-08 13:00:00 +0000 +0000'>November 8, 2025</span>&nbsp;·&nbsp;<span>4 min</span>&nbsp;·&nbsp;<span>721 words</span>&nbsp;·&nbsp;<span>Brandon Geraci</span></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#the-comprehensive-test-plan>The Comprehensive Test Plan</a><ul><li><a href=#test-matrix>Test Matrix</a></li><li><a href=#methodology>Methodology</a></li></ul></li><li><a href=#deepseek-7b-results>DeepSeek-7B Results</a></li><li><a href=#gpt-oss-120b-results>GPT-OSS-120B Results</a></li><li><a href=#qwen25-72b-results>Qwen2.5-72B Results</a></li><li><a href=#the-pattern-container-overhead-scales>The Pattern: Container Overhead Scales</a></li><li><a href=#performance-parity-the-good-news>Performance Parity: The Good News</a></li><li><a href=#the-kv-cache-revelation>The KV Cache Revelation</a></li><li><a href=#temperature-analysis>Temperature Analysis</a></li><li><a href=#data-quality-and-reproducibility>Data Quality and Reproducibility</a></li><li><a href=#interactive-charts>Interactive Charts</a></li><li><a href=#what-this-proves>What This Proves</a></li></ul></nav></div></details></div><div class=post-content><h2 id=the-comprehensive-test-plan>The Comprehensive Test Plan<a hidden class=anchor aria-hidden=true href=#the-comprehensive-test-plan>#</a></h2><p>Anecdotes are interesting. Single data points are suggestive. But <strong>60 benchmark runs</strong> across multiple models? That&rsquo;s science.</p><p>Here&rsquo;s what I did:</p><h3 id=test-matrix>Test Matrix<a hidden class=anchor aria-hidden=true href=#test-matrix>#</a></h3><ul><li><strong>3 Models</strong>:<ul><li>DeepSeek-R1-Distill-Qwen-7B (7 billion parameters)</li><li>Qwen2.5-72B-Instruct (72 billion parameters)</li><li>GPT-OSS-120B (120 billion parameters, MXFP4 quantized)</li></ul></li><li><strong>2 Environments</strong>: Native (chroot) vs Container (Docker)</li><li><strong>10 Iterations</strong> per model per environment</li><li><strong>Total</strong>: 60 benchmark runs</li></ul><h3 id=methodology>Methodology<a hidden class=anchor aria-hidden=true href=#methodology>#</a></h3><ul><li><strong>Framework</strong>: TensorRT-LLM (<code>trtllm-bench</code> CLI)</li><li><strong>Workload</strong>: 50 requests, 128 output tokens per request</li><li><strong>Cooldown</strong>: 5 minutes + GPU temp check (&lt; 45°C) between runs</li><li><strong>Duration</strong>: ~14 hours total</li><li><strong>Metrics</strong>: Peak memory, KV cache, throughput, latency, temperature</li></ul><h2 id=deepseek-7b-results>DeepSeek-7B Results<a hidden class=anchor aria-hidden=true href=#deepseek-7b-results>#</a></h2><p>My smallest model, but the most shocking results:</p><table><thead><tr><th>Metric</th><th>Native</th><th>Container</th><th>Difference</th></tr></thead><tbody><tr><td><strong>Peak Memory</strong></td><td>70.47 GiB</td><td>101.30 GiB</td><td><strong>+30.83 GiB (44% overhead!)</strong></td></tr><tr><td><strong>KV Cache</strong></td><td>44.31 GiB</td><td>16.57 GiB</td><td><strong>-27.74 GiB (63% less!)</strong></td></tr><tr><td><strong>Throughput</strong></td><td>119.79 tok/s</td><td>119.40 tok/s</td><td>0.3% difference</td></tr><tr><td><strong>Std Dev (σ)</strong></td><td>0.55</td><td>0.16</td><td>Very stable</td></tr></tbody></table><p><strong>Analysis</strong>: The 7B model shows the <strong>largest overhead</strong> at 30.8GB. Container KV cache is reduced to only <strong>37% of native</strong>. That&rsquo;s massive.</p><h2 id=gpt-oss-120b-results>GPT-OSS-120B Results<a hidden class=anchor aria-hidden=true href=#gpt-oss-120b-results>#</a></h2><p>The largest model (120B params, though MoE means 5.1B active):</p><table><thead><tr><th>Metric</th><th>Native</th><th>Container</th><th>Difference</th></tr></thead><tbody><tr><td><strong>Peak Memory</strong></td><td>71.72 GiB</td><td>93.43 GiB</td><td><strong>+21.71 GiB (30% overhead)</strong></td></tr><tr><td><strong>KV Cache</strong></td><td>43.19 GiB</td><td>23.65 GiB</td><td><strong>-19.54 GiB (45% less)</strong></td></tr><tr><td><strong>Throughput</strong></td><td>120.26 tok/s</td><td>120.41 tok/s</td><td>-0.1% difference</td></tr><tr><td><strong>Std Dev (σ)</strong></td><td>0.32</td><td>0.54</td><td>Very stable</td></tr></tbody></table><p><strong>Analysis</strong>: Despite being the largest model, GPT-OSS shows moderate overhead due to MXFP4 quantization. Native still has <strong>1.8x more KV cache</strong>.</p><h2 id=qwen25-72b-results>Qwen2.5-72B Results<a hidden class=anchor aria-hidden=true href=#qwen25-72b-results>#</a></h2><p>The 72B parameter model - the sweet spot:</p><table><thead><tr><th>Metric</th><th>Native</th><th>Container</th><th>Difference</th></tr></thead><tbody><tr><td><strong>Peak Memory</strong></td><td>70.03 GiB</td><td>90.02 GiB</td><td><strong>+19.99 GiB (29% overhead)</strong></td></tr><tr><td><strong>KV Cache</strong></td><td>44.71 GiB</td><td>26.72 GiB</td><td><strong>-17.99 GiB (40% less)</strong></td></tr><tr><td><strong>Throughput</strong></td><td>119.33 tok/s</td><td>119.51 tok/s</td><td>-0.2% difference</td></tr><tr><td><strong>Std Dev (σ)</strong></td><td>0.28</td><td>0.20</td><td>Very stable</td></tr></tbody></table><p><strong>Analysis</strong>: Qwen shows <strong>the most efficient memory usage</strong> of all models. Native mode has the <strong>highest KV cache</strong> at 44.71 GiB - even more than the 7B model!</p><h2 id=the-pattern-container-overhead-scales>The Pattern: Container Overhead Scales<a hidden class=anchor aria-hidden=true href=#the-pattern-container-overhead-scales>#</a></h2><p>Look at the overhead across models:</p><table><thead><tr><th>Model</th><th>Size</th><th>Overhead</th><th>Pattern</th></tr></thead><tbody><tr><td>DeepSeek</td><td>7B</td><td><strong>+30.83 GiB (44%)</strong></td><td>Highest %</td></tr><tr><td>Qwen</td><td>72B</td><td><strong>+19.99 GiB (29%)</strong></td><td>Middle</td></tr><tr><td>GPT-OSS</td><td>120B</td><td><strong>+21.71 GiB (30%)</strong></td><td>Middle</td></tr></tbody></table><p><strong>Insight</strong>: Overhead appears proportional to base memory usage, not model size. This suggests Docker&rsquo;s cgroup accounting scales with allocation size, confirming our unified memory double-counting theory.</p><h2 id=performance-parity-the-good-news>Performance Parity: The Good News<a hidden class=anchor aria-hidden=true href=#performance-parity-the-good-news>#</a></h2><p>Across all 60 runs, performance was virtually identical:</p><pre tabindex=0><code>Throughput Range:
- Native:    119.33 - 120.26 tokens/sec
- Container: 119.40 - 120.51 tokens/sec
- Difference: &lt; 0.3% (within margin of error)
</code></pre><p><strong>Standard deviations</strong> were incredibly low (σ &lt; 0.6 tokens/sec), showing:</p><ul><li>Excellent thermal management</li><li>Consistent GPU performance</li><li>No thermal throttling</li></ul><h2 id=the-kv-cache-revelation>The KV Cache Revelation<a hidden class=anchor aria-hidden=true href=#the-kv-cache-revelation>#</a></h2><p>This is the real story. Across all models:</p><table><thead><tr><th>Model</th><th>Native KV</th><th>Container KV</th><th>Ratio</th></tr></thead><tbody><tr><td>DeepSeek</td><td>44.31 GiB</td><td>16.57 GiB</td><td><strong>2.7x more</strong></td></tr><tr><td>GPT-OSS</td><td>43.19 GiB</td><td>23.65 GiB</td><td><strong>1.8x more</strong></td></tr><tr><td>Qwen</td><td>44.71 GiB</td><td>26.72 GiB</td><td><strong>1.7x more</strong></td></tr></tbody></table><p>Native mode provides <strong>1.7-2.7x more KV cache</strong> across the board. This is huge for:</p><ul><li>Longer context windows</li><li>Higher batch sizes</li><li>Better concurrent request handling</li><li>Overall throughput scaling</li></ul><h2 id=temperature-analysis>Temperature Analysis<a hidden class=anchor aria-hidden=true href=#temperature-analysis>#</a></h2><p>Interestingly, containers ran slightly cooler:</p><table><thead><tr><th>Environment</th><th>Avg End Temp</th><th>Range</th></tr></thead><tbody><tr><td>Native</td><td>60.6°C</td><td>59-61°C</td></tr><tr><td>Container</td><td>58.6°C</td><td>57-59°C</td></tr></tbody></table><p><strong>Why?</strong> Container overhead means more time in cooldown between runs. Actual compute time is the same, but total wall time is longer due to additional memory management.</p><h2 id=data-quality-and-reproducibility>Data Quality and Reproducibility<a hidden class=anchor aria-hidden=true href=#data-quality-and-reproducibility>#</a></h2><p>All 60 runs completed successfully with:</p><ul><li>✅ <strong>0 failures</strong> - Every benchmark completed</li><li>✅ <strong>Consistent results</strong> - Very low standard deviations</li><li>✅ <strong>Proper thermal management</strong> - No throttling</li><li>✅ <strong>Comprehensive logging</strong> - Full metadata saved</li></ul><p>Raw data available: <a href=https://github.com/brandonrc/benchmark-spark/tree/main/results/comprehensive>GitHub - benchmark-spark/results</a></p><h2 id=interactive-charts>Interactive Charts<a hidden class=anchor aria-hidden=true href=#interactive-charts>#</a></h2><p>Want to explore the data visually? Check out our <a href=https://brandonrc.github.io/benchmark-spark/>interactive results page</a> with:</p><ul><li>Peak memory comparisons</li><li>KV cache allocation charts</li><li>Throughput performance graphs</li></ul><h2 id=what-this-proves>What This Proves<a hidden class=anchor aria-hidden=true href=#what-this-proves>#</a></h2><p>After 60 runs across 3 models, the findings are clear:</p><ol><li><strong>Container overhead is real</strong>: 20-30 GB consistently</li><li><strong>KV cache reduction is significant</strong>: 1.7-2.7x less in containers</li><li><strong>Performance is identical</strong>: No speed penalty for native execution</li><li><strong>Pattern is consistent</strong>: Happens across all model sizes</li><li><strong>Root cause confirmed</strong>: Unified memory + cgroup double-counting</li></ol><p>This isn&rsquo;t a fluke. This isn&rsquo;t a configuration error. This is a fundamental architectural mismatch.</p><p>Next up: What we learned, practical recommendations, and what we&rsquo;re investigating next (spoiler: that KV cache scaling is fascinating).</p><hr><p><strong>Previous</strong>: <a href=../03-unified-memory-revelation>← Part 3: The Unified Memory Revelation</a><br><strong>Next</strong>: <a href=../05-what-we-learned>Part 5: What We Learned (And What&rsquo;s Next) →</a></p><p><strong>GitHub Repo</strong>: <a href=https://github.com/brandonrc/benchmark-spark>benchmark-spark</a><br><strong>Interactive Charts</strong>: <a href=https://brandonrc.github.io/benchmark-spark/>Results Dashboard</a></p></div><footer class=post-footer><ul class=post-tags><li><a href=https://brandongeraci.com/tags/dgx-spark/>Dgx-Spark</a></li><li><a href=https://brandongeraci.com/tags/benchmarking/>Benchmarking</a></li><li><a href=https://brandongeraci.com/tags/data/>Data</a></li><li><a href=https://brandongeraci.com/tags/results/>Results</a></li></ul><nav class=paginav><a class=prev href=https://brandongeraci.com/projects/dgx-spark/05-what-we-learned/><span class=title>« Prev</span><br><span>What I Learned (And What's Next)</span>
</a><a class=next href=https://brandongeraci.com/projects/dgx-spark/03-unified-memory-revelation/><span class=title>Next »</span><br><span>The Unified Memory Revelation: Why Docker Double-Counts</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share The Data: 60 Runs Don't Lie on x" href="https://x.com/intent/tweet/?text=The%20Data%3a%2060%20Runs%20Don%27t%20Lie&amp;url=https%3a%2f%2fbrandongeraci.com%2fprojects%2fdgx-spark%2f04-the-data%2f&amp;hashtags=dgx-spark%2cbenchmarking%2cdata%2cresults"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share The Data: 60 Runs Don't Lie on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fbrandongeraci.com%2fprojects%2fdgx-spark%2f04-the-data%2f&amp;title=The%20Data%3a%2060%20Runs%20Don%27t%20Lie&amp;summary=The%20Data%3a%2060%20Runs%20Don%27t%20Lie&amp;source=https%3a%2f%2fbrandongeraci.com%2fprojects%2fdgx-spark%2f04-the-data%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share The Data: 60 Runs Don't Lie on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fbrandongeraci.com%2fprojects%2fdgx-spark%2f04-the-data%2f&title=The%20Data%3a%2060%20Runs%20Don%27t%20Lie"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share The Data: 60 Runs Don't Lie on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fbrandongeraci.com%2fprojects%2fdgx-spark%2f04-the-data%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share The Data: 60 Runs Don't Lie on whatsapp" href="https://api.whatsapp.com/send?text=The%20Data%3a%2060%20Runs%20Don%27t%20Lie%20-%20https%3a%2f%2fbrandongeraci.com%2fprojects%2fdgx-spark%2f04-the-data%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share The Data: 60 Runs Don't Lie on telegram" href="https://telegram.me/share/url?text=The%20Data%3a%2060%20Runs%20Don%27t%20Lie&amp;url=https%3a%2f%2fbrandongeraci.com%2fprojects%2fdgx-spark%2f04-the-data%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share The Data: 60 Runs Don't Lie on ycombinator" href="https://news.ycombinator.com/submitlink?t=The%20Data%3a%2060%20Runs%20Don%27t%20Lie&u=https%3a%2f%2fbrandongeraci.com%2fprojects%2fdgx-spark%2f04-the-data%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://brandongeraci.com/>Brandon's Technical Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>